# 2025-01-14 18:29:11 # [INFO]  Configuration:
# 2025-01-14 18:29:11 # 	 -> train_hr_folder       : data/DIV2K_train_HR
# 2025-01-14 18:29:11 # 	 -> valid_hr_folder       : data/DIV2K_valid_HR
# 2025-01-14 18:29:11 # 	 -> train_lr_folder       : data/DIV2K_train_LR
# 2025-01-14 18:29:11 # 	 -> valid_lr_folder       : data/DIV2K_valid_LR
# 2025-01-14 18:29:11 # 	 -> train_teacher_folder  : data/DIV2K_train_teacher
# 2025-01-14 18:29:11 # 	 -> valid_teacher_folder  : data/DIV2K_valid_teacher
# 2025-01-14 18:29:11 # 	 -> overwrite_teacher_data: False
# 2025-01-14 18:29:11 # 	 -> model_id              : stabilityai/stable-diffusion-x4-upscaler
# 2025-01-14 18:29:11 # 	 -> teacher_prompt        : a photo
# 2025-01-14 18:29:11 # 	 -> num_inference_steps   : 5
# 2025-01-14 18:29:11 # 	 -> guidance_scale        : 0.0
# 2025-01-14 18:29:11 # 	 -> batch_size            : 1
# 2025-01-14 18:29:11 # 	 -> epochs                : 500
# 2025-01-14 18:29:11 # 	 -> learning_rate         : 0.0001
# 2025-01-14 18:29:11 # 	 -> weight_decay          : 0.0
# 2025-01-14 18:29:11 # 	 -> up_factor             : 4
# 2025-01-14 18:29:11 # 	 -> device                : cuda
# 2025-01-14 18:29:11 # 	 -> exp_name              : exp
# 2025-01-14 18:29:11 # 	 -> log_path              : log
# 2025-01-14 18:29:11 # 	 -> optimizer             : Adam
# 2025-01-14 18:29:11 # 	 -> scheduler             : None
# 2025-01-14 18:29:11 # 	 -> warmup_ratio          : 0.1
# 2025-01-14 18:29:11 # 	 -> warmup_steps          : 0
# 2025-01-14 18:29:11 # 	 -> clip_max_norm         : 1.0
# 2025-01-14 18:29:11 # 	 -> seed                  : 1998
# 2025-01-14 18:29:11 # [Stage 1]  Preparing Low-Resolution Images
# 2025-01-14 18:29:11 # [Teacher]  Generating LR from training HR: data/DIV2K_train_HR, found 800 images.
# 2025-01-14 18:29:11 # [Teacher]  Generating LR from validation HR: data/DIV2K_valid_HR, found 100 images.
# 2025-01-14 18:29:11 # [Stage 2]  Generating Teacher Outputs
# 2025-01-14 18:29:11 # [Teacher]  All teacher outputs already exist, and overwrite_teacher_data=False. Skipping upscaling.
# 2025-01-14 18:29:11 # [Stage 3]  Student Training (Knowledge Distillation)
# 2025-01-14 18:29:11 # [Trainer] Starting knowledge distillation training...
